{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "from datetime import date\n",
    "import re\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from pacmap import PaCMAP\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import arxiv\n",
    "from sklearn.neighbors import KNeighborsTransformer\n",
    "from IPython.display import clear_output\n",
    "from datetime import date\n",
    "from datetime import timedelta\n",
    "from pymongo import MongoClient\n",
    "from datetime import datetime\n",
    "from torch import nn\n",
    "from database_utils import *\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "device = 'cpu'\n",
    "torch.device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class ClickedDataset(Dataset):\n",
    "    def __init__(self, abstracts, item_vectors,abstract_map):\n",
    "        self.item_vectors = item_vectors.astype(np.float32)\n",
    "        self.abstracts = abstracts\n",
    "        self.abstract_map = abstract_map\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.item_vectors)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "            \n",
    "        abstract = self.abstracts[self.abstract_map[idx]]\n",
    "        item_vecs = self.item_vectors[idx]\n",
    "        \n",
    "        sample = (abstract,item_vecs)\n",
    "\n",
    "        return sample    \n",
    "    \n",
    "class paperBERT(nn.Module):\n",
    "    def __init__(self, num_papers, latent_dim):\n",
    "        super(paperBERT, self).__init__()\n",
    "        self.longformer = AutoModel.from_pretrained('allenai/longformer-base-4096')\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained('allenai/longformer-base-4096')\n",
    "        \n",
    "        self.user_encoder = nn.Sequential(\n",
    "            nn.Linear(num_papers),\n",
    "            nn.Linear(512),\n",
    "            nn.Linear(512),\n",
    "        )\n",
    "        \n",
    "        self.linear1 = nn.Linear(768, 256)\n",
    "        self.linear2 = nn.Linear(256, latent_dim)\n",
    "        \n",
    "    def forward(self,data):\n",
    "        encoding = self.tokenizer.batch_encode_plus(data, return_tensors='pt', padding=True,\n",
    "                                                       truncation=True, add_special_tokens = True).to(device)\n",
    "        input_ids = encoding['input_ids']\n",
    "        attention_mask = encoding['attention_mask']\n",
    "        \n",
    "        model_output = self.longformer(\n",
    "               input_ids, \n",
    "               attention_mask=attention_mask)\n",
    "\n",
    "        # sequence_output has the following shape: (batch_size, sequence_length, 768)\n",
    "        sequence_output=  mean_pooling(model_output, attention_mask)\n",
    "        linear1_output = self.linear1(sequence_output.view(-1,768)) ## extract the 1st token's embeddings\n",
    "        linear2_output = self.linear2(linear1_output)\n",
    "\n",
    "        return linear2_output\n",
    "    \n",
    "    def train(self,data_loader,epochs):\n",
    "        criterion = nn.MSELoss() ## If required define your own criterion\n",
    "        optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()))\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            for batch in data_loader: ## If you have a DataLoader()  object to get the data.\n",
    "                \n",
    "                data = list(batch[0])\n",
    "                targets = batch[1] ## assuming that data loader returns a tuple of data and its targets\n",
    "                \n",
    "                optimizer.zero_grad()   \n",
    "                outputs = model(data)\n",
    "                outputs = torch.tanh(outputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def predict(self, data):\n",
    "        with torch.no_grad():\n",
    "            encoding = self.tokenizer.batch_encode_plus(data, return_tensors='pt', padding=True,\n",
    "                                                           truncation=True, add_special_tokens = True).to(device)\n",
    "            input_ids = encoding['input_ids']\n",
    "            attention_mask = encoding['attention_mask']\n",
    "\n",
    "            model_output = self.longformer(\n",
    "                   input_ids, \n",
    "                   attention_mask=attention_mask)\n",
    "\n",
    "            # sequence_output has the following shape: (batch_size, sequence_length, 768)\n",
    "            sequence_output=  mean_pooling(model_output, attention_mask)\n",
    "            print(sequence_output.shape)\n",
    "            linear1_output = self.linear1(sequence_output.view(-1,768)) ## extract the 1st token's embeddings\n",
    "            linear2_output = self.linear2(linear1_output)\n",
    "            outputs = torch.tanh(linear2_output)\n",
    "        return outputs.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0,
     5
    ]
   },
   "outputs": [],
   "source": [
    "def loss(X, Y, Z, mask, lam):\n",
    "    return np.sum( ((Y.T @ Z - X) ** 2)[mask] ) \\\n",
    "       + lam * np.linalg.norm(Y, ord=\"fro\") \\\n",
    "       + lam * np.linalg.norm(Z, ord=\"fro\")\n",
    "\n",
    "def approximate(data_dense, rank, lam,max_iteration=1000,Y_start=None,Z_start=None):\n",
    "    # initialize low-rank approximation matrix as a product of two \n",
    "    # Y @ Z = X_bar\n",
    "    data_mask = np.ones(data_dense.shape, dtype=np.bool)\n",
    "    if Y_start is not None and Z_start is not None:\n",
    "        Y = Y_start\n",
    "        Z = Z_start\n",
    "    else:\n",
    "        Y = np.random.randn(rank, data_dense.shape[0])\n",
    "        Z = np.random.randn(rank, data_dense.shape[1])\n",
    "\n",
    "    # calculation speedup\n",
    "    lam_I = lam * np.eye(rank)\n",
    "\n",
    "    # alternating least squares until convergence\n",
    "    prev_obj = loss(data_dense, Y, Z, data_mask, lam)\n",
    "    converged = False\n",
    "\n",
    "    print(\"Start objective:\", prev_obj)\n",
    "\n",
    "    prev_Y = Y.copy()\n",
    "    prev_Z = Z.copy()\n",
    "    for iteration in range(1, max_iteration + 1):\n",
    "        if iteration % 10 == 0:\n",
    "            print(\"Iteration:\", iteration)\n",
    "            print(\"Current objective:\", prev_obj)\n",
    "\n",
    "        # optimize Y based on current value of Z\n",
    "        for col in range(Y.shape[1]):\n",
    "            has_rating = data_mask[col]\n",
    "            ratings = data_dense[col, has_rating]\n",
    "            Z_relevant_columns = Z[:, has_rating]\n",
    "            regularized_cov = np.sum([c.reshape([-1, 1]) @ c.reshape([1, -1]) for\n",
    "                                    c in Z_relevant_columns.T], axis=0) + lam_I\n",
    "            weighted_sum = np.sum(Z_relevant_columns * ratings, axis=1)\n",
    "            Y[:, col] = np.linalg.inv(regularized_cov) @ weighted_sum\n",
    "\n",
    "        # optimize Z based on current values of Y\n",
    "        for col in range(Z.shape[1]):\n",
    "            has_rating = data_mask[:, col]\n",
    "            ratings = data_dense[has_rating, col]\n",
    "            Y_relevant_columns = Y[:, has_rating]\n",
    "            regularized_cov = np.sum([c.reshape([-1, 1]) @ c.reshape([1, -1]) for\n",
    "                                    c in Y_relevant_columns.T], axis=0) + lam_I\n",
    "            weighted_sum = np.sum(Y_relevant_columns * ratings, axis=1)\n",
    "            Z[:, col] = np.linalg.inv(regularized_cov) @ weighted_sum\n",
    "\n",
    "        obj = loss(data_dense, Y, Z, data_mask, lam)\n",
    "\n",
    "        # convergence criteria. prevents division by 0.\n",
    "        if abs(obj - prev_obj) / ( abs(prev_obj) + 1e-8 ) < TOLERANCE:\n",
    "            converged = True\n",
    "            break\n",
    "\n",
    "        prev_obj = obj\n",
    "\n",
    "    print(\"Converged:\", converged)\n",
    "    print(\"# iterations:\", iteration)\n",
    "    print(\"Final objective:\", obj)\n",
    "\n",
    "    # report final low-rank matrix\n",
    "    return Y.T, Z.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "code_folding": [
     9,
     26,
     39,
     52,
     62,
     81
    ]
   },
   "outputs": [],
   "source": [
    "PERPLEXITY=5\n",
    "g_kernel=1\n",
    "EPOCHS=2000\n",
    "LR=200\n",
    "MOMENTUM=0.99\n",
    "\n",
    "def getKey(item):\n",
    "    return item[1]\n",
    "\n",
    "def k_neighbours(x,x1_index,p_or_q='p'):\n",
    "    x1=x[x1_index]\n",
    "    list_k_neighbours=[]\n",
    "    for i in range(x.shape[0]):\n",
    "        if i!=x1_index:\n",
    "            xi=x[i]\n",
    "            if p_or_q=='p':\n",
    "                distance=np.exp(-np.linalg.norm(x1-xi)**2/(2*g_kernel**2))\n",
    "            else:\n",
    "                distance=(1+np.linalg.norm(x1-xi)**2)**-1\n",
    "            list_k_neighbours.append([i,distance])\n",
    "    \n",
    "    list_k_neighbours=sorted(list_k_neighbours,key=getKey)\n",
    "    return list_k_neighbours[:PERPLEXITY]\n",
    "\n",
    "#compute the similarity pij between two xi,xj in the original space\n",
    "#divide the distance between xi,xj by the sum of the distances of the k_neightbours where k is the complexity\n",
    "def compute_pij(x,x1_index,x2_index):\n",
    "    x1=x[x1_index]\n",
    "    x2=x[x2_index]\n",
    "    # num=(1+np.linalg.norm(x1-x2)**2)**(-1)/(2*g_kernel**2))\n",
    "    num=np.exp(-np.linalg.norm(x1-x2)**2)/(2*g_kernel**2)\n",
    "    denom=0\n",
    "    list_k_neighbours=k_neighbours(x,x1_index,'p')\n",
    "    for i in list_k_neighbours:\n",
    "        denom+=i[1]\n",
    "    return num/denom\n",
    "\n",
    "\n",
    "#compute the table p of the xij in the original space\n",
    "def compute_p(x):\n",
    "    table=np.zeros((x.shape[0],x.shape[0]))\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[0]):\n",
    "            if i!=j:\n",
    "                pij=compute_pij(x,i,j)\n",
    "                pji=compute_pij(x,j,i)\n",
    "                table[i,j]=(pij+pji)/(2*x.shape[0])\n",
    "                # table[i,j]=pij\n",
    "    return table\n",
    "\n",
    "#compute the similarity qij between two yi,yj in the new space\n",
    "#divide the distance between yi,yj by the sum of the distances of the k_neightbours where k is the complexity\n",
    "def compute_qij(y,y1_index,y2_index):\n",
    "    y1=y[y1_index]\n",
    "    y2=y[y2_index]\n",
    "    num=(1+np.linalg.norm(y1-y2)**2)**(-1)\n",
    "    denom=0\n",
    "    for i in k_neighbours(y,y1_index,'q'):\n",
    "        denom+=i[1]\n",
    "    return num/denom\n",
    "\n",
    "#compute the table q of the yij in the new space\n",
    "def compute_q(y):\n",
    "    table=np.zeros((y.shape[0],y.shape[0]))\n",
    "    for i in range(y.shape[0]):\n",
    "        for j in range(y.shape[0]):\n",
    "            if i!=j:\n",
    "                qij=compute_qij(y,i,j)\n",
    "                table[i,j]=qij\n",
    "    return table\n",
    "\n",
    "#compute the erros between the 2 distributions using the KL-divergence\n",
    "def kl_divergence(p,q):\n",
    "    total=0\n",
    "    for i in range(p.shape[0]):\n",
    "        for j in range(q.shape[0]):\n",
    "            if q[i,j]!=0 and p[i,j]!=0:\n",
    "                total+=p[i,j]*np.log(p[i,j]/q[i,j])\n",
    "    return total\n",
    "\n",
    "#apply gradient descent to lower the KL-divergence\n",
    "def gradient_descent(p,q,y):\n",
    "    for iter in range(EPOCHS):\n",
    "        for i in range(y.shape[0]):\n",
    "            sum_value=0\n",
    "            for j in range(y.shape[0]):\n",
    "                sum_value+=((y[i]-y[j])*(p[i,j]-q[i,j])*(1+np.linalg.norm(y[i]-y[j]**2))**-1)\n",
    "            y[i]-=4*LR*sum_value\n",
    "        if iter%100==0:\n",
    "            q=compute_q(y)\n",
    "            print(kl_divergence(p,q)) \n",
    "    y-=np.mean(y)\n",
    "    y/=np.std(y)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.0057338434021394\n",
      "-2.1335419988078357\n",
      "-1.9680415939387885\n",
      "-1.8914396273111955\n",
      "-1.9006524228198989\n",
      "-1.907040772273569\n",
      "-1.9121968860199015\n",
      "-1.9163363996108063\n",
      "-1.9197779080547117\n",
      "-1.9227015474756448\n",
      "-1.9253303471575576\n",
      "-1.9286719987634215\n",
      "-1.9318542212177308\n",
      "-1.9347427104220827\n",
      "-1.937375094134231\n",
      "-1.9397818032904157\n",
      "-1.9419879497534491\n",
      "-1.944014595473558\n",
      "-1.9459573495486664\n",
      "-1.9483910356004341\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "table_p=compute_p(abstracts)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "y = pca.fit_transform(abstracts)\n",
    "\n",
    "table_q=compute_q(y)\n",
    "y=gradient_descent(table_p,table_q,y)\n",
    "\n",
    "plt.scatter(y[:,0],y[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def generate_interaction_matrix():\n",
    "    client = MongoClient(URI)\n",
    "    \n",
    "    # get all users recently viewed\n",
    "    db = client.papers.users\n",
    "    \n",
    "    all_viewed = db.find({},{\"recently_viewed\":1})\n",
    "    users_viewed = list(all_viewed)\n",
    "    \n",
    "    # get all papers and their ids\n",
    "    db = client.papers.papers\n",
    "    \n",
    "    all_paper_ids = db.find({\"number_of_clicks\":{\"$gt\":0}},{\"_id\":1})\n",
    "    all_ids = list(all_paper_ids)\n",
    "    \n",
    "    # make dictionary between paper id and index in array\n",
    "    paper_index_map = {}\n",
    "    \n",
    "    i=0\n",
    "    for dic in all_ids:\n",
    "        paper_index_map[dic[\"_id\"]] = i\n",
    "        i+=1\n",
    "    \n",
    "    # make array of zeroes with shape (users,papers)\n",
    "    clicked = np.zeros((len(users_viewed),len(all_ids)))\n",
    "    print(clicked.shape)\n",
    "    # for all users recently viewed change 0 in array to a 1\n",
    "    user_index_map = {}\n",
    "    i=0\n",
    "    for user in users_viewed:\n",
    "        user_index_map[user[\"_id\"]] = i\n",
    "        \n",
    "        for paper in user[\"recently_viewed\"]:\n",
    "            if paper in paper_index_map:\n",
    "                clicked[i,paper_index_map[int(paper)]] = 1\n",
    "        \n",
    "        i+=1\n",
    "    \n",
    "    return clicked,user_index_map, paper_index_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def user_factorize(data, paper_vectors, latent_dim,learnining_rate=.1,lmbda=.1,lmbda2=.05,user_start=None, max_iter=1000):\n",
    "    pca = PCA(n_components=latent_dim)\n",
    "    U_comp =pca.fit_transform(paper_vectors).T\n",
    "    m,n = data.shape\n",
    "    P = np.random.uniform(0,latent_dim**.5,size=(latent_dim,m))\n",
    "    \n",
    "    U = np.random.uniform(0,latent_dim**.5,size=(latent_dim,n))\n",
    "    U = U_comp\n",
    "    \n",
    "    loss = []\n",
    "    \n",
    "    users, items = data.nonzero()\n",
    "    \n",
    "    for i in range(max_iter):\n",
    "        for u,p in zip(users, items):\n",
    "            error = data[u,p] - U[:,p]*P[:,u]\n",
    "            P[:,u] += learnining_rate * (error * U[:,p] - lmbda* P[:,u])\n",
    "            U[:,p] += learnining_rate * (error * P[:,u] - lmbda* U[:,p])\n",
    "            \n",
    "        total_error = np.linalg.norm(data- P.T@U,\"fro\") \n",
    "        loss.append(total_error)\n",
    "    return P.T, U.T, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "P,U,loss = user_factorize(rat, abstracts, 2,learnining_rate=.1, max_iter=200,lmbda=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pca = PCA(n_components=2)\n",
    "y = pca.fit_transform(abstracts)\n",
    "plt.scatter(y[:,0],y[:,1],c=range(12))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(U[:,0],U[:,1],c=range(12))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x180e23f7a08>]"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred =P@U.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 9.99999999e-01,  9.99999999e-01,  9.99999953e-01,\n",
       "          9.99999952e-01, -4.07106118e-10, -7.24073823e-10,\n",
       "         -1.39822294e-09, -9.34775931e-10,  9.99999997e-01,\n",
       "          9.99999964e-01,  9.99999968e-01,  1.00000000e+00],\n",
       "        [-6.03631056e-10, -1.11466760e-09,  4.74049188e-08,\n",
       "          4.63252212e-08,  1.00000000e+00,  9.99999999e-01,\n",
       "          9.99999998e-01,  9.99999999e-01, -2.20293969e-11,\n",
       "          3.54067091e-08,  3.09508313e-08, -1.30431733e-15],\n",
       "        [ 9.99999999e-01,  9.99999999e-01,  9.99999953e-01,\n",
       "          9.99999952e-01, -4.07104120e-10, -7.24071825e-10,\n",
       "         -1.39822094e-09, -9.34773933e-10,  9.99999997e-01,\n",
       "          9.99999964e-01,  9.99999968e-01,  1.00000000e+00]]),\n",
       " array([[1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1.]]))"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred,rat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstracts,new_map = get_abstracts_by_ids(paper_index_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start objective: 3848.4516061954655\n",
      "Converged: True\n",
      "# iterations: 8\n",
      "Final objective: 5.518658841793084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerModel: ['lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing LongformerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LongformerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "paperBERT(\n",
       "  (longformer): LongformerModel(\n",
       "    (embeddings): LongformerEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(4098, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): LongformerEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): LongformerLayer(\n",
       "          (attention): LongformerAttention(\n",
       "            (self): LongformerSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): LongformerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): LongformerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): LongformerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): LongformerLayer(\n",
       "          (attention): LongformerAttention(\n",
       "            (self): LongformerSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): LongformerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): LongformerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): LongformerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): LongformerLayer(\n",
       "          (attention): LongformerAttention(\n",
       "            (self): LongformerSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): LongformerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): LongformerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): LongformerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): LongformerLayer(\n",
       "          (attention): LongformerAttention(\n",
       "            (self): LongformerSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): LongformerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): LongformerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): LongformerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): LongformerLayer(\n",
       "          (attention): LongformerAttention(\n",
       "            (self): LongformerSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): LongformerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): LongformerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): LongformerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): LongformerLayer(\n",
       "          (attention): LongformerAttention(\n",
       "            (self): LongformerSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): LongformerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): LongformerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): LongformerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): LongformerLayer(\n",
       "          (attention): LongformerAttention(\n",
       "            (self): LongformerSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): LongformerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): LongformerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): LongformerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): LongformerLayer(\n",
       "          (attention): LongformerAttention(\n",
       "            (self): LongformerSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): LongformerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): LongformerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): LongformerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): LongformerLayer(\n",
       "          (attention): LongformerAttention(\n",
       "            (self): LongformerSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): LongformerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): LongformerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): LongformerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): LongformerLayer(\n",
       "          (attention): LongformerAttention(\n",
       "            (self): LongformerSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): LongformerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): LongformerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): LongformerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): LongformerLayer(\n",
       "          (attention): LongformerAttention(\n",
       "            (self): LongformerSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): LongformerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): LongformerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): LongformerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): LongformerLayer(\n",
       "          (attention): LongformerAttention(\n",
       "            (self): LongformerSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): LongformerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): LongformerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): LongformerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): LongformerPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (linear1): Linear(in_features=768, out_features=256, bias=True)\n",
       "  (linear2): Linear(in_features=256, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "latent_dim = 2\n",
    "MAX_ITERATION = 1000\n",
    "TOLERANCE = 1e-4\n",
    "\n",
    "# Get clicked matrix along with the mappings \n",
    "rat,user_index_map,paper_index_map = generate_interaction_matrix()\n",
    "\n",
    "# Factorize matrix\n",
    "U,P = approximate(rat, latent_dim, 1)\n",
    "\n",
    "# get abstracts for input to longformer\n",
    "abstracts,new_map = get_abstracts_by_ids(paper_index_map)\n",
    "\n",
    "# Make PyTorch data loader\n",
    "dataset = ClickedDataset(abstracts, P,new_map)\n",
    "data_loader = DataLoader(dataset, batch_size=10,shuffle=True)\n",
    "\n",
    "# Create Model\n",
    "model = paperBERT(latent_dim) # You can pass the parameters if required to have more flexible model\n",
    "model.to(device) ## can be gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 768])\n"
     ]
    }
   ],
   "source": [
    "papers_latent_prediction_before_train = model.predict(list(abstracts[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01132876, -0.23788672,  0.23825852, -0.02143954,  0.00349622,\n",
       "         0.05581367, -0.04997552,  0.09560195, -0.03817378, -0.02161047]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U@papers_latent_prediction_before_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rat[0,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(data_loader,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 768])\n"
     ]
    }
   ],
   "source": [
    "papers_latent_prediction_after_train = model.predict(list(abstracts[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.000986  ,  0.000987  , -0.00341318,  0.00641557, -0.00110761,\n",
       "        -0.000543  ,  0.00429675,  0.00060941,  0.00138234, -0.00150365],\n",
       "       [ 0.00098602,  0.00098701, -0.00341317,  0.00641559, -0.0011076 ,\n",
       "        -0.00054299,  0.00429678,  0.00060939,  0.00138236, -0.00150365],\n",
       "       [ 0.00098598,  0.00098703, -0.00341321,  0.00641562, -0.00110759,\n",
       "        -0.00054298,  0.00429678,  0.00060939,  0.00138233, -0.00150368],\n",
       "       [ 0.00098598,  0.00098704, -0.0034132 ,  0.00641558, -0.00110761,\n",
       "        -0.00054294,  0.00429673,  0.00060936,  0.00138234, -0.00150369],\n",
       "       [ 0.00098598,  0.000987  , -0.0034132 ,  0.00641561, -0.0011076 ,\n",
       "        -0.00054297,  0.00429674,  0.00060939,  0.00138235, -0.0015037 ],\n",
       "       [ 0.000986  ,  0.00098701, -0.00341316,  0.00641561, -0.00110759,\n",
       "        -0.00054298,  0.00429677,  0.0006094 ,  0.00138233, -0.00150367],\n",
       "       [ 0.00098598,  0.00098702, -0.00341321,  0.00641561, -0.0011076 ,\n",
       "        -0.00054295,  0.00429678,  0.00060938,  0.00138235, -0.00150368],\n",
       "       [ 0.000986  ,  0.000987  , -0.0034132 ,  0.0064156 , -0.00110759,\n",
       "        -0.00054298,  0.00429679,  0.00060938,  0.00138234, -0.00150367],\n",
       "       [ 0.000986  ,  0.00098699, -0.00341317,  0.0064156 , -0.00110762,\n",
       "        -0.00054295,  0.00429674,  0.00060938,  0.00138235, -0.00150369],\n",
       "       [ 0.00098602,  0.000987  , -0.00341318,  0.00641559, -0.00110761,\n",
       "        -0.00054301,  0.00429678,  0.00060939,  0.00138235, -0.00150366]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers_latent_prediction_after_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerModel: ['lm_head.dense.bias', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing LongformerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LongformerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "get_last_days_papers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
